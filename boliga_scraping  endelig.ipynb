{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.distance import geodesic\n",
    "import tqdm.notebook as tqdm\n",
    "from collections import Counter\n",
    "import lemmy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Boliga website for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "\n",
    "def houses_boliga(number_houses):\n",
    "    \"\"\"\n",
    "    Returns a list of all ids for houses on boliga\n",
    "    \"\"\"\n",
    "    house_id = list()\n",
    "    url = \"https://www.boliga.dk/resultat\"\n",
    "    \n",
    "    for i in range(int(number_houses/50)):\n",
    "        new_url = url + f\"?page={i}\"\n",
    "        response = requests.get(new_url)\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html,\"html.parser\")\n",
    "        ids = soup.find_all(\"a\",{\"class\":\"house-list-item\"})\n",
    "        link_houses = list()\n",
    "\n",
    "        for link in ids:\n",
    "            link_houses.append(re.findall(\"(/\\d{4,}/)\",link[\"href\"])[0].replace(\"/\",\"\"))\n",
    "        \n",
    "        house_id.extend(link_houses)\n",
    "        \n",
    "    return house_id\n",
    "\n",
    "def get_info(id_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Take an list with ids of houses on boliga and gets specific data about these ids\n",
    "    \n",
    "    \"\"\"\n",
    "    all_df = list()\n",
    "    new_keys = [\"registeredArea\",\"downPayment\",\"estateUrl\",\"currentArchiveId\",\"forSaleNowId\",\n",
    "                \"foreclosureId\",\"selfsaleEstateId\",\"cleanStreet\",\"estateId\",\"latitude\",\"longitude\",\n",
    "               \"propertyType\",\"priceChangePercentTotal\",\"energyClass\",\"price\",\"rooms\",\"size\",\"lotSize\",\n",
    "               \"floor\",\"buildYear\",\"city\",\"isActive\",\"municipality\",\"zipCode\",\"street\",\n",
    "                \"squaremeterPrice\",\"daysForSale\",\"createdDate\",\"basementSize\",\"views\"]\n",
    "    \n",
    "    for house_id in id_list:\n",
    "        response = requests.get(f'https://api.boliga.dk/api/v2/estate/{house_id}')\n",
    "        response = response.json()\n",
    "        df_dict = {key: response[key] for key in new_keys}\n",
    "        df = pd.DataFrame(df_dict,index=[0])\n",
    "        all_df.append(df)\n",
    "\n",
    "    df = pd.concat(all_df,axis=0,ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_reviews(df):\n",
    "    bodys = list()\n",
    "    #Finder alle ejendomsmæglere, som har mere end 100 huse til salg\n",
    "    for value in df[\"estateUrl\"].values:\n",
    "        estates.append(value[8:15])\n",
    "    numbers = dict(Counter(estates))\n",
    "    over_100 = dict() \n",
    "    for key, value in numbers.items():\n",
    "        if value > 100:\n",
    "            over_100[key] = value\n",
    "    #Kører igennem alle links og finder tilhørende beskrivelse\n",
    "    for link in tqdm.tqdm(df[\"estateUrl\"].values):\n",
    "        try:\n",
    "            response = requests.get(link)\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html,\"html.parser\")\n",
    "            \n",
    "            if link[8:15] ==\"home.dk\": #Home\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"text\"},\"p\")\n",
    "                bodys.extend([x.p.text.replace(\"\\n\",\"\").strip().lower() for x in ids[0:1] if len(x)>1])\n",
    "            elif link[8:15] ==\"ww.skbo\": #skbolig\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"listing-text\"})\n",
    "                bodys.extend([sk.text.replace(\"\\n\",\"\").replace(\"\\r\",\"\").strip().lower() for sk in ids[0:1] if len(sk)>1])\n",
    "            elif link[8:15] == \"www.nyb\": #Nybolig\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"foldable-spot__container\"})\n",
    "                bodys.extend([ny.text.replace(\"\\n\",\"\").strip().lower() for ny in ids[0:1] if len(ny)>1])\n",
    "            elif link [8:15] == \"ww.elto\": #Eltoft Nielsen\n",
    "                ids = soup.find_all(\"br\")\n",
    "                bodys.extend([elto.text.replace(\"\\n\",\"\").strip().lower() for elto in ids[0:1] if len(elto)>1])\n",
    "            elif link[8:15] == \"www.cla\": #Claus Borg\n",
    "                ids = soup.find_all(\"div\",{\"id\":\"case_content\"})\n",
    "                bodys.extend([cla.text.replace(\"\\n\",\"\").strip().lower() for cla in ids[0:1] if len(cla)>1])\n",
    "            elif link[8:15] == \"www.lok\": #Lokalbolig\n",
    "                ids = soup.find_all(\"p\")\n",
    "                loka = [lok.text.replace(\"\\n\",\"\").strip().lower() for lok in ids if len(lok.text)>100]\n",
    "                bodys.extend([''.join(loka)])\n",
    "            elif link[8:15] == \"www.edc\": #EDC Bolig\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"description\"})\n",
    "                bodys.extend([edc.text.replace(\"\\n\",\"\").strip().lower() for edc in ids[0:1] if len(edc)>1])\n",
    "            elif link[8:15] == \"adamsch\": #Adam Schnack\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"listing-text\"})\n",
    "                bodys.extend([adam.text.replace(\"\\n\",\"\").strip().lower() for adam in ids[0:1] if len(adam)>1])\n",
    "            elif link[8:20] == \"www.estate.d\": #Estate\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"property-description\"})\n",
    "                bodys.extend([est.text.replace(\"\\n\",\"\").strip().lower() for est in ids[0:1] if len(est)>1])\n",
    "            elif link[8:15] == \"www.bri\": #Brikk Ejendomme\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"prop-user-content\"})\n",
    "                bodys.extend([bri.text.replace(\"\\n\",\"\").strip().lower() for bri in ids[0:1] if len(bri)>1])\n",
    "            elif link[8:15] == \"www.rea\": #Realmæglerne\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"text-full\"})\n",
    "                bodys.extend([rea.text.replace(\"\\n\",\"\").strip().lower() for rea in ids[0:1] if len(rea)>1])\n",
    "            elif link[8:15] == \"danboli\": #Danbolig\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"db-description-block\"})\n",
    "                bodys.extend([dan.text.replace(\"\\n\",\"\").strip().lower() for dan in ids[0:1] if len(dan)>1])\n",
    "            elif link[8:15] == \"ww.lili\": #Lillenhof\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"inner\"})\n",
    "                bodys.extend([dan.text.replace(\"\\n\",\"\").strip().lower() for dan in ids[0:1] if len(dan)>10])\n",
    "            elif link[8:15] == \"bjornby\":\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"content d-md-block d-none wrap-content\"})\n",
    "                bodys.extend([bjor.text.replace(\"\\n\",\"\").strip() for bjor in ids[0:1] if len(bjor)>10])\n",
    "            elif link[8:15] == 'www.hov': #Hovmand\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"column\"})\n",
    "                bodys.extend([hov.text.replace(\"\\n\",\"\").strip() for hov in ids[0:1] if len(hov)>1])\n",
    "            elif link[8:15] == 'ww.jesp': #Jesper Nielsen\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"case-description\"})\n",
    "                bodys.extend([jesp.text.replace(\"\\n\",\"\").strip() for jesp in ids[0:1] if len(jesp)>1])\n",
    "            elif link[8:15] == \"www.sel\": #Selvsalg\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"tab-pane active fade in\"})\n",
    "                bodys.extend([selv.text.replace(\"\\n\",\"\").strip() for selv in ids[0:1] if len(selv)>1])\n",
    "            elif link[8:15] == \"www.bol\": #Bolig\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"description col-md-16\"})\n",
    "                bodys.extend([bol.text.replace(\"\\n\",\"\").strip() for bol in ids[0:1] if len(bol)>1])\n",
    "            elif link[8:15] == 'www.joh': #Johns\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"column\"})\n",
    "                bodys.extend([john.text.replace(\"\\n\",\"\").strip() for john in ids[0:1] if len(john)>1])\n",
    "            elif link[8:15] == \"racking\": #Robinhus\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"text-container\"})\n",
    "                bodys.extend([robin.text.replace(\"\\n\",\"\").strip() for robin in ids[0:1] if len(robin)>1])\n",
    "            elif link[8:15] == \"www.min\": #minbolighandel\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"description col-md-16\"})\n",
    "                bodys.extend([minb.text.replace(\"\\n\",\"\").strip() for minb in ids[0:1] if len(minb)>1])\n",
    "            elif link[8:15] == \"ww.unni\": #Unnibolig\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"column\"})\n",
    "                bodys.extend([un.text.replace(\"\\n\",\"\").strip() for un in ids[0:1] if len(un)>1])\n",
    "            elif link[8:15] == \"www.sdb\": #Sdb bolig\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"column\"})\n",
    "                bodys.extend([un.text.replace(\"\\n\",\"\").strip() for un in ids[0:1] if len(un)>1])\n",
    "            elif link[8:15] == \"ww.land\":#Landobolig\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"col-md-8\"})\n",
    "                bodys.extend([land.text.replace(\"\\n\",\"\").strip() for land in ids[0:1] if len(land)>1])\n",
    "            elif link[8:15] == \"www.ber\": #Bermistof\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"column\"})\n",
    "                bodys.extend([ber.text.replace(\"\\n\",\"\").strip() for ber in ids[0:1] if len(ber)>1])\n",
    "            elif link [8:20] == 'www.carlsber': #Carlsberg Byen\n",
    "                ids = soup.find_all(\"div\",{\"itemprop\":\"description\"})\n",
    "                bodys.extend([car.text.replace(\"\\n\",\"\").strip() for car in ids[0:1] if len(car)>1])\n",
    "            elif link[8:15] == \"www.car\": #Carsten Nordbo\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"description col-md-16\"})\n",
    "                bodys.extend([car.text.replace(\"\\n\",\"\").strip() for car in ids[0:1] if len(car)>1])\n",
    "            elif link[8:15] == 'ww.agri': \n",
    "                ids = soup.find_all(\"div\",{\"class\":\"col-md-8 col-sm-7 hidden-xs text-box desktop\"})\n",
    "                bodys.extend([agr.text.replace(\"\\n\",\"\").strip() for agr in ids[0:1] if len(agr)>1])\n",
    "            elif link[8:15] == \"www.pla\":#Place2Live\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"col-lg-16\"})\n",
    "                bodys.extend([pla.text.replace(\"\\n\",\"\").strip() for pla in ids[0:1] if len(pla)>1])\n",
    "            elif link[8:15] == \"www.vil\": #Villadsenbolig\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"description col-md-16\"})\n",
    "                bodys.extend([vil.text.replace(\"\\n\",\"\").strip() for vil in ids[0:1] if len(vil)>1])\n",
    "            elif link[8:15] == 'maegler': #Mæglerhuset\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"case-text\"})\n",
    "                bodys.extend([mae.text.replace(\"\\n\",\"\").strip() for mae in ids[0:1] if len(mae)>1])\n",
    "            elif link[8:15] == 'ww.thom': #ThomasJørgensen\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"description col-md-16\"})\n",
    "                bodys.extend([thom.text.replace(\"\\n\",\"\").strip() for thom in ids[0:1] if len(thom)>1])\n",
    "            elif link[8:15] == 'www.htb': #HTbolig\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"left-side global-style\"})\n",
    "                bodys.extend([htb.text.replace(\"\\n\",\"\").strip() for htb in ids[0:1] if len(htb)>1])\n",
    "            elif link[8:15] == 'ww.boli': #Boligone\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"first-col\"})\n",
    "                bodys.extend([bol.text.replace(\"\\n\",\"\").strip() for bol in ids[0:1] if len(bol)>1])\n",
    "            elif link[8:15] == \"www.mæg\":#Mæglerringen\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"first-col\"})\n",
    "                bodys.extend([ma.text.replace(\"\\n\",\"\").strip() for ma in ids[0:1] if len(ma)>1])\n",
    "            elif link[8:15] == \"ww.vest\":\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"first-col\"})\n",
    "                bodys.extend([vest.text.replace(\"\\n\",\"\").strip() for vest in ids[0:1] if len(vest)>1])\n",
    "            elif link[8:15] == \"www.tho\": #Thorregård\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"annonce rammebaggrund\"})\n",
    "                bodys.extend([th.text.replace(\"\\n\",\"\").strip() for th in ids[0:1] if len(th)>1])\n",
    "            elif link[8:15] == \"byggegr\": #Byggegrund\n",
    "                ids = soup.find_all(\"div\",{\"class\":\"section section-12\"})\n",
    "                bodys.extend([byg.text.replace(\"\\n\",\"\").strip() for byg in ids[0:1] if len(byg)>1])\n",
    "            elif link[8:15] == \"grundsa\": #Grundsalg\n",
    "                bodys.append(np.nan)\n",
    "            elif link[8:15] == \"rundsal\": #Grundsalg\n",
    "                bodys.append(np.nan)\n",
    "            elif link[8:15] ==\"ww.paul\": #paulun\n",
    "                bodys.append(np.nan)\n",
    "            else:\n",
    "                bodys.append(np.nan)\n",
    "                if link[8:15] in over_100:\n",
    "                    print(\"Missing\", link[8:15])\n",
    "        except:\n",
    "            print(link,\"virkede ikke\")\n",
    "            continue\n",
    "    \n",
    "    return bodys\n",
    "\n",
    "def find_realtors(df):\n",
    "    \"\"\"\n",
    "    This function finds all realtors, who has more that 100 houses for sale.\n",
    "    Used to find the structure for all realtors of relevance\n",
    "    \"\"\"\n",
    "    realtors_link = list()\n",
    "    #Finder alle ejendomsmæglere, som har mere end 100 huse til salg\n",
    "    estates = list()\n",
    "    for value in df[\"estateUrl\"].values:\n",
    "        estates.append(value[8:15])\n",
    "    numbers = dict(Counter(estates))\n",
    "\n",
    "    over_100 = dict() \n",
    "    for key, value in numbers.items():\n",
    "        if value > 100:\n",
    "            over_100[key] = value\n",
    "    already_accounted = list()\n",
    "    for link in tqdm.tqdm(df[\"estateUrl\"].values):        \n",
    "        if link[8:15] in over_100.keys():\n",
    "            if link[8:15] not in already_accounted:\n",
    "                print(link,\"not in loop\")\n",
    "                print(link[8:15])\n",
    "                realtors_link.append(link[8:15])\n",
    "                already_accounted.append(link[8:15])\n",
    "\n",
    "    return realtors_link\n",
    "    \n",
    "def preprocess_csv(csv):\n",
    "    \"\"\"\n",
    "    This function loads the dataset from boliga annd preproccesses it.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv)\n",
    "    y = df[\"price\"].values\n",
    "    #generating dummy variables - Property type\n",
    "    housing_type={1:'villa',2:'raekkehuse', 3:'ejerlejlighed',4:'fritidshus', 5:'andel',6:'landejendom', \n",
    "              7:'helrsgrund',8:'fritidsgrund', 9:'villalejlighed',10:'andet_1',11:\"andet_2\",12:\"andet_3\"}\n",
    "    dummy_df = pd.get_dummies(df['propertyType'])   \n",
    "    df = df.join(dummy_df)\n",
    "    df.drop(\"propertyType\",axis=1,inplace=True)\n",
    "    df.rename(columns = housing_type,inplace=True)\n",
    "    \n",
    "    X = np.array(df[[\"size\",\"registeredArea\",\"priceChangePercentTotal\",\"rooms\",\"size\",\"lotSize\",\n",
    "                    \"floor\",\"buildYear\",\"basementSize\",\"daysForSale\",\"villa\",\"raekkehuse\",\"ejerlejlighed\",\n",
    "                    \"fritidshus\",\"andel\",\"landejendom\",\"helrsgrund\",\"fritidsgrund\",\"villalejlighed\",\n",
    "                    \"andet_2\",\"andet_3\"]])\n",
    "    \n",
    "    return X, y, df\n",
    "\n",
    "def preprocess_text(string):\n",
    "    lemmatizer = lemmy.load(\"da\")\n",
    "    string = lemmatizer.lemmatize(\"\",string)[0].split()\n",
    "\n",
    "    return string\n",
    "\n",
    "def words_count(list_of_strings):\n",
    "    sentences = list_of_strings\n",
    "    counts = dict(Counter(sentences))\n",
    "    return counts\n",
    "\n",
    "def add_lonlat(df,df_station):\n",
    "    min_dist = list()\n",
    "    for location in tqdm(df[\"location\"]):\n",
    "        distance = list()\n",
    "        for lon,lat in zip(df_station[\"lon\"],df_station[\"lat\"]):\n",
    "            distance.append(geodesic((lat,lon), location).km)\n",
    "    \n",
    "        min_dist.append(min(distance))\n",
    "        \n",
    "    df[\"dist_station\"] = min_dist\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52093"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, df = preprocess_csv(\"house_data.csv\")\n",
    "len(np.array(df[\"estateUrl\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>registeredArea</th>\n",
       "      <th>downPayment</th>\n",
       "      <th>estateUrl</th>\n",
       "      <th>currentArchiveId</th>\n",
       "      <th>forSaleNowId</th>\n",
       "      <th>foreclosureId</th>\n",
       "      <th>selfsaleEstateId</th>\n",
       "      <th>cleanStreet</th>\n",
       "      <th>estateId</th>\n",
       "      <th>...</th>\n",
       "      <th>raekkehuse</th>\n",
       "      <th>ejerlejlighed</th>\n",
       "      <th>fritidshus</th>\n",
       "      <th>andel</th>\n",
       "      <th>landejendom</th>\n",
       "      <th>helrsgrund</th>\n",
       "      <th>fritidsgrund</th>\n",
       "      <th>villalejlighed</th>\n",
       "      <th>andet_2</th>\n",
       "      <th>andet_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>225000</td>\n",
       "      <td>https://home.dk/boligkatalog/koebenhavn/1051/e...</td>\n",
       "      <td>1676546</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nyhavn</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>430000</td>\n",
       "      <td>https://www.nybolig.dk/ejerlejlighed/1051/nyha...</td>\n",
       "      <td>1688236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nyhavn</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>460000</td>\n",
       "      <td>http://www.skbolig.dk/sag.asp?sagsnr=221920&amp;mg...</td>\n",
       "      <td>1672807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nyhavn</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>146</td>\n",
       "      <td>550000</td>\n",
       "      <td>http://www.skbolig.dk/sag.asp?sagsnr=333420&amp;mg...</td>\n",
       "      <td>1694633</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nyhavn</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>182</td>\n",
       "      <td>625000</td>\n",
       "      <td>http://www.skbolig.dk/sag.asp?sagsnr=331320&amp;mg...</td>\n",
       "      <td>1689738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nyhavn</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  registeredArea  downPayment  \\\n",
       "0           0              68       225000   \n",
       "1           1              78       430000   \n",
       "2           2             117       460000   \n",
       "3           3             146       550000   \n",
       "4           4             182       625000   \n",
       "\n",
       "                                           estateUrl  currentArchiveId  \\\n",
       "0  https://home.dk/boligkatalog/koebenhavn/1051/e...           1676546   \n",
       "1  https://www.nybolig.dk/ejerlejlighed/1051/nyha...           1688236   \n",
       "2  http://www.skbolig.dk/sag.asp?sagsnr=221920&mg...           1672807   \n",
       "3  http://www.skbolig.dk/sag.asp?sagsnr=333420&mg...           1694633   \n",
       "4  http://www.skbolig.dk/sag.asp?sagsnr=331320&mg...           1689738   \n",
       "\n",
       "   forSaleNowId  foreclosureId  selfsaleEstateId cleanStreet  estateId  ...  \\\n",
       "0             0              0                 0      Nyhavn         0  ...   \n",
       "1             0              0                 0      Nyhavn         0  ...   \n",
       "2             0              0                 0      Nyhavn         0  ...   \n",
       "3             0              0                 0      Nyhavn         0  ...   \n",
       "4             0              0                 0      Nyhavn         0  ...   \n",
       "\n",
       "   raekkehuse  ejerlejlighed  fritidshus andel  landejendom  helrsgrund  \\\n",
       "0           0              1           0     0            0           0   \n",
       "1           0              1           0     0            0           0   \n",
       "2           0              1           0     0            0           0   \n",
       "3           0              1           0     0            0           0   \n",
       "4           0              1           0     0            0           0   \n",
       "\n",
       "   fritidsgrund  villalejlighed  andet_2  andet_3  \n",
       "0             0               0        0        0  \n",
       "1             0               0        0        0  \n",
       "2             0               0        0        0  \n",
       "3             0               0        0        0  \n",
       "4             0               0        0        0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
